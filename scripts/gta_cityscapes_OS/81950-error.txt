2024-06-21 10:23:03,905 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
CUDA available: True
GPU 0: Tesla V100S-PCIE-32GB
CUDA_HOME: /data/software/default/cuda/11.4
NVCC: Build cuda_11.4.r11.4/compiler.30188945_0
GCC: gcc (GCC) 10.3.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.4.0
MMCV: 1.3.7
MMCV Compiler: GCC 8.5
MMCV CUDA Compiler: not available
MMSegmentation: 0.16.0+920becf
------------------------------------------------------------

2024-06-21 10:23:03,905 - mmseg - INFO - Distributed training: False
2024-06-21 10:23:04,741 - mmseg - INFO - Config:
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
norm_cfg = dict(type='BN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder',
    pretrained='pretrained/mit_b5.pth',
    backbone=dict(type='mit_b5', style='pytorch'),
    decode_head=dict(
        type='DAFormerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        channels=256,
        dropout_ratio=0.1,
        num_classes=20,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(
            embed_dims=256,
            embed_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),
            embed_neck_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),
            fusion_cfg=dict(
                type='aspp',
                sep=True,
                dilations=(1, 6, 12, 18),
                pool=False,
                act_cfg=dict(type='ReLU'),
                norm_cfg=dict(type='BN', requires_grad=True))),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(
        work_dir=
        'work_dirs/local-basic/240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41'
    ),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = 'data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
gta_train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1280, 720)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
cityscapes_train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 512)),
    dict(type='RandomCrop', crop_size=(512, 512)),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=4,
    train=dict(
        type='UDADataset',
        source=dict(
            type='GTADataset',
            data_root='data/gta/',
            img_dir='images',
            ann_dir='labels',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(type='Resize', img_scale=(1280, 720)),
                dict(
                    type='RandomCrop',
                    crop_size=(512, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ]),
        target=dict(
            type='CityscapesDataset',
            data_root='data/cityscapes/',
            img_dir='leftImg8bit/train',
            ann_dir='gtFine/train',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(type='Resize', img_scale=(1024, 512)),
                dict(type='RandomCrop', crop_size=(512, 512)),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ]),
        rare_class_sampling=dict(
            min_pixels=3000, class_temp=0.01, min_crop_ratio=0.5)),
    val=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
uda = dict(
    type='DACS',
    alpha=0.999,
    pseudo_threshold=0.968,
    pseudo_weight_ignore_top=15,
    pseudo_weight_ignore_bottom=120,
    imnet_feature_dist_lambda=0.005,
    imnet_feature_dist_classes=[6, 7, 11, 12, 13, 14, 15, 16, 17, 18],
    imnet_feature_dist_scale_min_ratio=0.75,
    mix='class',
    blur=True,
    color_jitter_strength=0.2,
    color_jitter_probability=0.2,
    debug_img_interval=500,
    print_grad_magnitude=False,
    unknown_label=19,
    start_unknown=4000)
use_ddp_wrapper = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            head=dict(lr_mult=10.0),
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = None
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
seed = 0
n_gpus = 1
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)
evaluation = dict(interval=1000, metric='mIoU')
name = '240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41'
exp = 'basic'
name_dataset = 'gta2cityscapes'
name_architecture = 'daformer_sepaspp_mitb5'
name_encoder = 'mitb5'
name_decoder = 'daformer_sepaspp'
name_uda = 'dacs_a999_fd_things_rcs0.01_cpl'
name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'
work_dir = 'work_dirs/local-basic/240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41'
git_rev = '920becf14fddc14ec0676f3dc532bac9c155a971'
gpu_ids = range(0, 1)

2024-06-21 10:23:04,741 - mmseg - INFO - Set random seed to 0, deterministic: False
/data/groups/rozaripf/REU_2024/UDA/DAFormer/mmseg/models/backbones/mix_transformer.py:216: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
2024-06-21 10:23:06,601 - mmseg - INFO - Load mit checkpoint.
2024-06-21 10:23:06,601 - mmseg - INFO - Use load_from_local loader
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/cnn/utils/weight_init.py:118: UserWarning: init_cfg without layer key, if you do not define override key either, this init_cfg will do nothing
  warnings.warn(
2024-06-21 10:23:07,096 - mmseg - INFO - Load mit checkpoint.
2024-06-21 10:23:07,096 - mmseg - INFO - Use load_from_local loader
2024-06-21 10:23:07,321 - mmseg - INFO - Load mit checkpoint.
2024-06-21 10:23:07,321 - mmseg - INFO - Use load_from_local loader
2024-06-21 10:23:07,548 - mmseg - INFO - DACS(
  (model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss()
      )
      (conv_seg): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
  (ema_model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss()
      )
      (conv_seg): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
  (imnet_model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): ModuleList(
        (0): CrossEntropyLoss()
      )
      (conv_seg): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2024-06-21 10:23:08,898 - mmseg - INFO - Loaded 24966 images from data/gta/images
2024-06-21 10:23:08,953 - mmseg - INFO - Loaded 2975 images from data/cityscapes/leftImg8bit/train
2024-06-21 10:23:09,073 - mmseg - INFO - RCS Classes: [18, 17, 6, 15, 4, 3, 9, 13, 8, 1, 10, 2, 0]
2024-06-21 10:23:09,074 - mmseg - INFO - RCS ClassProb: [2.3663391e-01 2.2957228e-01 2.0376408e-01 1.5526883e-01 1.1414617e-01
 2.7925171e-02 1.9752422e-02 1.2886332e-02 3.5001514e-05 1.5736989e-05
 3.5661998e-08 7.0569828e-10 1.5235276e-17]
2024-06-21 10:23:23,787 - mmseg - INFO - Loaded 500 images from data/cityscapes/leftImg8bit/val
2024-06-21 10:23:23,788 - mmseg - INFO - Start running, host: wangad0448@gpu03, work_dir: /data/groups/rozaripf/REU_2024/UDA/DAFormer/work_dirs/local-basic/240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 10:23:23,788 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:24:25,054 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 12:43:54, time: 1.147, data_time: 0.036, memory: 9812, decode.loss_ce: 2.6055, decode.acc_seg: 11.6309, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 1.3990, mix.decode.acc_seg: 15.7105
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:25:18,942 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 12:19:50, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 2.3742, decode.acc_seg: 53.0799, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 1.1973, mix.decode.acc_seg: 42.6453
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:26:13,005 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 12:11:59, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 1.9370, decode.acc_seg: 64.6920, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.9379, mix.decode.acc_seg: 63.3070
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:27:07,066 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 12:07:36, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 1.4596, decode.acc_seg: 65.8334, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.7527, mix.decode.acc_seg: 67.6700
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:28:00,980 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 12:04:13, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 1.2226, decode.acc_seg: 66.9923, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.5685, mix.decode.acc_seg: 70.0786
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:28:55,120 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 12:02:10, time: 1.083, data_time: 0.014, memory: 9812, decode.loss_ce: 0.9948, decode.acc_seg: 70.3991, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.5031, mix.decode.acc_seg: 73.7889
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:29:49,356 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 12:00:37, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.8062, decode.acc_seg: 73.4302, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.4295, mix.decode.acc_seg: 74.2584
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:30:43,310 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 11:58:46, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.7207, decode.acc_seg: 70.4909, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.3663, mix.decode.acc_seg: 75.8400
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:31:37,389 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 11:57:19, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.6807, decode.acc_seg: 72.0480, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.3794, mix.decode.acc_seg: 75.0674
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:32:31,458 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 11:55:57, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.5116, decode.acc_seg: 76.1340, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2793, mix.decode.acc_seg: 77.7319
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:33:27,457 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 11:56:59, time: 1.120, data_time: 0.014, memory: 9812, decode.loss_ce: 0.4984, decode.acc_seg: 76.7861, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2857, mix.decode.acc_seg: 78.1741
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:34:21,444 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 11:55:29, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.4497, decode.acc_seg: 76.5289, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2514, mix.decode.acc_seg: 79.0434
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:35:15,478 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 11:54:08, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.4207, decode.acc_seg: 78.2406, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2401, mix.decode.acc_seg: 78.7557
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:36:09,573 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 11:52:54, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.4004, decode.acc_seg: 77.2730, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2004, mix.decode.acc_seg: 77.9618
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:37:03,754 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 11:51:47, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.3511, decode.acc_seg: 78.7396, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1842, mix.decode.acc_seg: 77.3915
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:37:57,866 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 11:50:38, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.3413, decode.acc_seg: 78.0810, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1788, mix.decode.acc_seg: 78.8819
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:38:51,931 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 11:49:29, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.3084, decode.acc_seg: 78.1840, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1980, mix.decode.acc_seg: 79.6478
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:39:46,121 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 11:48:27, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2694, decode.acc_seg: 80.5081, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1425, mix.decode.acc_seg: 78.7334
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:40:40,124 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 11:47:18, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2648, decode.acc_seg: 81.2414, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1494, mix.decode.acc_seg: 81.6860
2024-06-21 10:43:12,310 - mmseg - INFO - per class results:
2024-06-21 10:43:12,312 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 86.71 | 98.46 |
|    sidewalk   | 22.88 | 26.44 |
|    building   | 78.03 | 86.98 |
|      wall     | 18.71 | 53.17 |
|     fence     | 12.59 | 14.57 |
|      pole     |  nan  |  nan  |
| traffic light |  6.91 |  6.95 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 82.44 | 92.72 |
|    terrain    | 28.11 | 60.69 |
|      sky      |  75.1 | 89.91 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 79.31 | 93.21 |
|     truck     |  nan  |  nan  |
|      bus      | 32.06 | 61.51 |
|     train     |  nan  |  nan  |
|   motorcycle  | 16.69 | 72.42 |
|    bicycle    | 34.94 | 43.26 |
|    unknown    |  0.0  |  0.0  |
+---------------+-------+-------+
2024-06-21 10:43:12,312 - mmseg - INFO - Summary:
2024-06-21 10:43:12,313 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 84.35 | 41.03 | 57.16 |   0.0   |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:43:12,315 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 10:43:12,315 - mmseg - INFO - Iter [500/40000]	lr: 3.896e-05, eta: 11:46:10, time: 1.080, data_time: 0.014, memory: 9812, aAcc: 0.8435, mIoU: 0.4103, mAcc: 0.5716, IoU.road: 0.8671, IoU.sidewalk: 0.2288, IoU.building: 0.7803, IoU.wall: 0.1871, IoU.fence: 0.1259, IoU.pole: nan, IoU.traffic light: 0.0691, IoU.traffic sign: nan, IoU.vegetation: 0.8244, IoU.terrain: 0.2811, IoU.sky: 0.7510, IoU.person: nan, IoU.rider: nan, IoU.car: 0.7931, IoU.truck: nan, IoU.bus: 0.3206, IoU.train: nan, IoU.motorcycle: 0.1669, IoU.bicycle: 0.3494, IoU.unknown: 0.0000, Acc.road: 0.9846, Acc.sidewalk: 0.2644, Acc.building: 0.8698, Acc.wall: 0.5317, Acc.fence: 0.1457, Acc.pole: nan, Acc.traffic light: 0.0695, Acc.traffic sign: nan, Acc.vegetation: 0.9272, Acc.terrain: 0.6069, Acc.sky: 0.8991, Acc.person: nan, Acc.rider: nan, Acc.car: 0.9321, Acc.truck: nan, Acc.bus: 0.6151, Acc.train: nan, Acc.motorcycle: 0.7242, Acc.bicycle: 0.4326, Acc.unknown: 0.0000, decode.loss_ce: 0.3636, decode.acc_seg: 77.4032, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2363, mix.decode.acc_seg: 76.4388
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:44:07,820 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 12:46:42, time: 3.074, data_time: 1.979, memory: 9812, decode.loss_ce: 0.2879, decode.acc_seg: 80.7731, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1872, mix.decode.acc_seg: 78.5749
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:45:01,788 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 12:42:43, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2563, decode.acc_seg: 81.0504, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1521, mix.decode.acc_seg: 78.0682
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:45:55,831 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 12:39:03, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2419, decode.acc_seg: 79.9617, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1463, mix.decode.acc_seg: 80.1697
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:46:49,796 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 12:35:34, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2226, decode.acc_seg: 80.5674, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1358, mix.decode.acc_seg: 80.2900
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:47:43,758 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 12:32:18, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2487, decode.acc_seg: 82.2411, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1704, mix.decode.acc_seg: 80.5042
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:48:37,684 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 12:29:11, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2827, decode.acc_seg: 79.9564, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1871, mix.decode.acc_seg: 80.1895
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:49:31,596 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 12:26:14, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2616, decode.acc_seg: 80.1936, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1397, mix.decode.acc_seg: 79.2595
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:50:25,659 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 12:23:29, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2569, decode.acc_seg: 78.4862, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1621, mix.decode.acc_seg: 79.2945
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:51:19,763 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 12:20:54, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2657, decode.acc_seg: 82.9298, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1579, mix.decode.acc_seg: 81.2206
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:52:13,952 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 12:18:27, time: 1.084, data_time: 0.016, memory: 9812, decode.loss_ce: 0.3032, decode.acc_seg: 79.4051, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1895, mix.decode.acc_seg: 80.4442
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:53:09,838 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 12:16:48, time: 1.118, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2593, decode.acc_seg: 80.5649, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1757, mix.decode.acc_seg: 82.1022
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:54:03,860 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 12:14:28, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2100, decode.acc_seg: 81.4883, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1368, mix.decode.acc_seg: 83.3734
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:54:57,946 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 12:12:14, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2083, decode.acc_seg: 82.1805, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1367, mix.decode.acc_seg: 82.4949
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:55:52,035 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 12:10:04, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2475, decode.acc_seg: 79.1838, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2117, mix.decode.acc_seg: 80.3261
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:56:46,222 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 12:08:02, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2850, decode.acc_seg: 79.3555, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2434, mix.decode.acc_seg: 78.6823
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:57:40,218 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 12:05:59, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2378, decode.acc_seg: 81.8579, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2083, mix.decode.acc_seg: 82.0920
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:58:34,195 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 12:03:59, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2082, decode.acc_seg: 83.1051, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1782, mix.decode.acc_seg: 81.8992
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 10:59:28,296 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 12:02:05, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2589, decode.acc_seg: 80.1297, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2088, mix.decode.acc_seg: 80.8418
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:00:22,386 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 12:00:14, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1790, decode.acc_seg: 83.5002, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1526, mix.decode.acc_seg: 85.2958
2024-06-21 11:02:55,058 - mmseg - INFO - per class results:
2024-06-21 11:02:55,059 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 86.48 | 98.37 |
|    sidewalk   | 14.59 |  16.1 |
|    building   | 80.71 | 90.79 |
|      wall     | 26.84 | 52.45 |
|     fence     | 21.43 | 24.24 |
|      pole     |  nan  |  nan  |
| traffic light | 35.58 | 45.92 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 82.05 | 93.72 |
|    terrain    |  34.1 | 67.59 |
|      sky      | 83.12 | 97.01 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 80.71 | 93.62 |
|     truck     |  nan  |  nan  |
|      bus      | 31.18 | 64.56 |
|     train     |  nan  |  nan  |
|   motorcycle  | 18.94 | 64.67 |
|    bicycle    | 24.24 | 26.16 |
|    unknown    |  0.0  |  0.0  |
+---------------+-------+-------+
2024-06-21 11:02:55,059 - mmseg - INFO - Summary:
2024-06-21 11:02:55,060 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 85.12 | 44.28 | 59.66 |   0.0   |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:02:55,062 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 11:02:55,062 - mmseg - INFO - Iter [500/40000]	lr: 5.700e-05, eta: 11:58:27, time: 1.082, data_time: 0.015, memory: 9812, aAcc: 0.8512, mIoU: 0.4428, mAcc: 0.5966, IoU.road: 0.8648, IoU.sidewalk: 0.1459, IoU.building: 0.8071, IoU.wall: 0.2684, IoU.fence: 0.2143, IoU.pole: nan, IoU.traffic light: 0.3558, IoU.traffic sign: nan, IoU.vegetation: 0.8205, IoU.terrain: 0.3410, IoU.sky: 0.8312, IoU.person: nan, IoU.rider: nan, IoU.car: 0.8071, IoU.truck: nan, IoU.bus: 0.3118, IoU.train: nan, IoU.motorcycle: 0.1894, IoU.bicycle: 0.2424, IoU.unknown: 0.0000, Acc.road: 0.9837, Acc.sidewalk: 0.1610, Acc.building: 0.9079, Acc.wall: 0.5245, Acc.fence: 0.2424, Acc.pole: nan, Acc.traffic light: 0.4592, Acc.traffic sign: nan, Acc.vegetation: 0.9372, Acc.terrain: 0.6759, Acc.sky: 0.9701, Acc.person: nan, Acc.rider: nan, Acc.car: 0.9362, Acc.truck: nan, Acc.bus: 0.6456, Acc.train: nan, Acc.motorcycle: 0.6467, Acc.bicycle: 0.2616, Acc.unknown: 0.0000, decode.loss_ce: 0.2093, decode.acc_seg: 82.2203, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1671, mix.decode.acc_seg: 83.9499
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:03:50,596 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 12:27:33, time: 3.082, data_time: 1.986, memory: 9812, decode.loss_ce: 0.1944, decode.acc_seg: 83.2124, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1843, mix.decode.acc_seg: 83.1782
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:04:44,501 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 12:25:00, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2040, decode.acc_seg: 81.1563, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1887, mix.decode.acc_seg: 83.3169
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:05:38,439 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 12:22:32, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1796, decode.acc_seg: 82.9655, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1834, mix.decode.acc_seg: 84.6247
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:06:32,391 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 12:20:09, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1621, decode.acc_seg: 83.4528, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1542, mix.decode.acc_seg: 86.6972
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:07:26,353 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 12:17:50, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1696, decode.acc_seg: 81.5808, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1660, mix.decode.acc_seg: 84.2595
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:08:20,335 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 12:15:35, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1661, decode.acc_seg: 83.5513, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1676, mix.decode.acc_seg: 84.5981
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:09:14,252 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 12:13:23, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1530, decode.acc_seg: 81.1145, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1563, mix.decode.acc_seg: 84.3917
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:10:08,185 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 12:11:14, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1574, decode.acc_seg: 82.7106, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1691, mix.decode.acc_seg: 83.0969
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:11:02,166 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 12:09:09, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1944, decode.acc_seg: 82.6270, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1991, mix.decode.acc_seg: 82.2861
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:11:56,132 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 12:07:06, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1516, decode.acc_seg: 83.6090, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1755, mix.decode.acc_seg: 84.5044
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:12:52,007 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 12:05:34, time: 1.117, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1610, decode.acc_seg: 82.5816, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1696, mix.decode.acc_seg: 84.1229
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:13:45,984 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 12:03:36, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1504, decode.acc_seg: 83.3563, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1730, mix.decode.acc_seg: 84.7543
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:14:40,042 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 12:01:42, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1597, decode.acc_seg: 83.4710, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1688, mix.decode.acc_seg: 85.1366
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:15:34,226 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 11:59:52, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1269, decode.acc_seg: 85.1950, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1408, mix.decode.acc_seg: 85.5132
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:16:28,375 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 11:58:03, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.2260, decode.acc_seg: 82.2534, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2221, mix.decode.acc_seg: 83.5828
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:17:22,401 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 11:56:15, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1858, decode.acc_seg: 81.9408, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1888, mix.decode.acc_seg: 83.8924
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:18:16,584 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 11:54:30, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1437, decode.acc_seg: 84.6956, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1621, mix.decode.acc_seg: 87.5783
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:19:10,640 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 11:52:46, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1864, decode.acc_seg: 85.1356, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2119, mix.decode.acc_seg: 85.8024
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:20:04,602 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 11:51:02, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1413, decode.acc_seg: 84.4030, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1601, mix.decode.acc_seg: 84.5576
2024-06-21 11:22:37,092 - mmseg - INFO - per class results:
2024-06-21 11:22:37,093 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 89.59 | 96.46 |
|    sidewalk   | 34.78 | 42.34 |
|    building   | 79.23 | 96.08 |
|      wall     | 43.68 | 56.25 |
|     fence     |  4.17 |  4.24 |
|      pole     |  nan  |  nan  |
| traffic light |  38.3 | 53.32 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 85.31 | 91.94 |
|    terrain    | 44.79 | 63.06 |
|      sky      | 81.17 | 99.15 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 83.83 | 94.26 |
|     truck     |  nan  |  nan  |
|      bus      | 35.97 | 78.18 |
|     train     |  nan  |  nan  |
|   motorcycle  | 28.51 |  72.1 |
|    bicycle    |  51.1 | 65.47 |
|    unknown    |  0.0  |  0.0  |
+---------------+-------+-------+
2024-06-21 11:22:37,093 - mmseg - INFO - Summary:
2024-06-21 11:22:37,093 - mmseg - INFO - 
+-------+-------+------+---------+
|  aAcc |  mIoU | mAcc | H-Score |
+-------+-------+------+---------+
| 86.96 | 50.03 | 65.2 |   0.0   |
+-------+-------+------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:22:37,095 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 11:22:37,096 - mmseg - INFO - Iter [500/40000]	lr: 5.550e-05, eta: 11:49:20, time: 1.078, data_time: 0.014, memory: 9812, aAcc: 0.8696, mIoU: 0.5003, mAcc: 0.6520, IoU.road: 0.8959, IoU.sidewalk: 0.3478, IoU.building: 0.7923, IoU.wall: 0.4368, IoU.fence: 0.0417, IoU.pole: nan, IoU.traffic light: 0.3830, IoU.traffic sign: nan, IoU.vegetation: 0.8531, IoU.terrain: 0.4479, IoU.sky: 0.8117, IoU.person: nan, IoU.rider: nan, IoU.car: 0.8383, IoU.truck: nan, IoU.bus: 0.3597, IoU.train: nan, IoU.motorcycle: 0.2851, IoU.bicycle: 0.5110, IoU.unknown: 0.0000, Acc.road: 0.9646, Acc.sidewalk: 0.4234, Acc.building: 0.9608, Acc.wall: 0.5625, Acc.fence: 0.0424, Acc.pole: nan, Acc.traffic light: 0.5332, Acc.traffic sign: nan, Acc.vegetation: 0.9194, Acc.terrain: 0.6306, Acc.sky: 0.9915, Acc.person: nan, Acc.rider: nan, Acc.car: 0.9426, Acc.truck: nan, Acc.bus: 0.7818, Acc.train: nan, Acc.motorcycle: 0.7210, Acc.bicycle: 0.6547, Acc.unknown: 0.0000, decode.loss_ce: 0.1817, decode.acc_seg: 82.4995, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1813, mix.decode.acc_seg: 84.5136
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:23:33,147 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 12:07:59, time: 3.093, data_time: 1.987, memory: 9812, decode.loss_ce: 0.1527, decode.acc_seg: 81.9631, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1595, mix.decode.acc_seg: 85.6716
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:24:27,217 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 12:06:00, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1682, decode.acc_seg: 83.3869, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1843, mix.decode.acc_seg: 86.9786
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:25:21,353 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 12:04:03, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1552, decode.acc_seg: 83.8575, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1564, mix.decode.acc_seg: 85.3380
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:26:15,346 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 12:02:07, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1615, decode.acc_seg: 82.7081, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1611, mix.decode.acc_seg: 86.6471
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:27:09,312 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 12:00:13, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1887, decode.acc_seg: 82.9536, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1705, mix.decode.acc_seg: 85.3004
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:28:03,247 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 11:58:20, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1327, decode.acc_seg: 85.0862, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1498, mix.decode.acc_seg: 87.7660
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:28:57,200 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 11:56:29, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1445, decode.acc_seg: 83.7114, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1583, mix.decode.acc_seg: 86.4148
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:29:51,353 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 11:54:42, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1655, decode.acc_seg: 82.3663, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1731, mix.decode.acc_seg: 86.3574
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:30:45,505 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 11:52:57, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1641, decode.acc_seg: 84.6230, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1851, mix.decode.acc_seg: 85.7728
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:31:39,623 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 11:51:12, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1411, decode.acc_seg: 83.6206, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1510, mix.decode.acc_seg: 87.3735
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:32:35,077 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 11:49:43, time: 1.109, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1759, decode.acc_seg: 84.4395, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1939, mix.decode.acc_seg: 86.2838
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:33:29,202 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 11:48:01, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1801, decode.acc_seg: 83.6726, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2155, mix.decode.acc_seg: 84.3763
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:34:23,199 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 11:46:20, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1790, decode.acc_seg: 82.4069, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1951, mix.decode.acc_seg: 85.3639
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:35:17,273 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 11:44:40, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1388, decode.acc_seg: 83.5493, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1587, mix.decode.acc_seg: 85.8292
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:36:11,270 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 11:43:01, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1603, decode.acc_seg: 83.4194, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1633, mix.decode.acc_seg: 85.7821
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:37:05,196 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 11:41:22, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1381, decode.acc_seg: 85.7899, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1673, mix.decode.acc_seg: 86.7935
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:37:59,347 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 11:39:47, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1586, decode.acc_seg: 80.5392, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1860, mix.decode.acc_seg: 85.1210
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:38:53,379 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 11:38:11, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1494, decode.acc_seg: 83.2464, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1436, mix.decode.acc_seg: 87.0541
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:39:47,284 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 11:36:35, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1361, decode.acc_seg: 83.9871, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1443, mix.decode.acc_seg: 86.1273
2024-06-21 11:42:20,221 - mmseg - INFO - per class results:
2024-06-21 11:42:20,222 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 91.06 |  97.9 |
|    sidewalk   | 47.11 | 55.28 |
|    building   |  81.1 | 94.53 |
|      wall     | 37.44 | 50.21 |
|     fence     | 15.48 | 16.34 |
|      pole     |  nan  |  nan  |
| traffic light | 39.39 | 48.96 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 86.21 | 94.35 |
|    terrain    | 41.23 | 50.73 |
|      sky      | 84.95 | 99.06 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 84.27 | 95.85 |
|     truck     |  nan  |  nan  |
|      bus      | 38.72 |  78.3 |
|     train     |  nan  |  nan  |
|   motorcycle  | 27.39 | 61.79 |
|    bicycle    | 52.72 | 65.37 |
|    unknown    |  0.0  |  0.0  |
+---------------+-------+-------+
2024-06-21 11:42:20,223 - mmseg - INFO - Summary:
2024-06-21 11:42:20,223 - mmseg - INFO - 
+-------+-------+------+---------+
|  aAcc |  mIoU | mAcc | H-Score |
+-------+-------+------+---------+
| 88.32 | 51.93 | 64.9 |   0.0   |
+-------+-------+------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:42:20,225 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 11:42:20,225 - mmseg - INFO - Iter [500/40000]	lr: 5.400e-05, eta: 11:35:01, time: 1.079, data_time: 0.014, memory: 9812, aAcc: 0.8832, mIoU: 0.5193, mAcc: 0.6490, IoU.road: 0.9106, IoU.sidewalk: 0.4711, IoU.building: 0.8110, IoU.wall: 0.3744, IoU.fence: 0.1548, IoU.pole: nan, IoU.traffic light: 0.3939, IoU.traffic sign: nan, IoU.vegetation: 0.8621, IoU.terrain: 0.4123, IoU.sky: 0.8495, IoU.person: nan, IoU.rider: nan, IoU.car: 0.8427, IoU.truck: nan, IoU.bus: 0.3872, IoU.train: nan, IoU.motorcycle: 0.2739, IoU.bicycle: 0.5272, IoU.unknown: 0.0000, Acc.road: 0.9790, Acc.sidewalk: 0.5528, Acc.building: 0.9453, Acc.wall: 0.5021, Acc.fence: 0.1634, Acc.pole: nan, Acc.traffic light: 0.4896, Acc.traffic sign: nan, Acc.vegetation: 0.9435, Acc.terrain: 0.5073, Acc.sky: 0.9906, Acc.person: nan, Acc.rider: nan, Acc.car: 0.9585, Acc.truck: nan, Acc.bus: 0.7830, Acc.train: nan, Acc.motorcycle: 0.6179, Acc.bicycle: 0.6537, Acc.unknown: 0.0000, decode.loss_ce: 0.1440, decode.acc_seg: 83.9804, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1468, mix.decode.acc_seg: 86.5950
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:43:16,167 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 11:48:25, time: 3.098, data_time: 1.994, memory: 9812, decode.loss_ce: 0.2308, decode.acc_seg: 83.3857, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.4754, mix.decode.acc_seg: 75.3435
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:44:10,122 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 11:46:40, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1839, decode.acc_seg: 81.4218, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2587, mix.decode.acc_seg: 75.8421
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:45:04,185 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 11:44:58, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1753, decode.acc_seg: 82.5502, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2488, mix.decode.acc_seg: 79.8097
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:45:58,286 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 11:43:17, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1774, decode.acc_seg: 81.7725, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2607, mix.decode.acc_seg: 77.6888
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:46:52,431 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 11:41:38, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1616, decode.acc_seg: 84.2198, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2526, mix.decode.acc_seg: 80.6605
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:47:46,568 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 11:40:00, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1421, decode.acc_seg: 83.8561, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1929, mix.decode.acc_seg: 80.9494
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:48:40,574 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 11:38:22, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1390, decode.acc_seg: 83.4105, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1983, mix.decode.acc_seg: 83.0680
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:49:34,455 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 11:36:43, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1799, decode.acc_seg: 83.6576, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2336, mix.decode.acc_seg: 82.3162
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:50:28,360 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 11:35:06, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1449, decode.acc_seg: 84.6144, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1961, mix.decode.acc_seg: 83.4763
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:51:22,286 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 11:33:30, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1377, decode.acc_seg: 84.5371, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2159, mix.decode.acc_seg: 80.2350
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:52:17,560 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 11:32:06, time: 1.105, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1278, decode.acc_seg: 84.5203, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1826, mix.decode.acc_seg: 82.8081
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:53:11,597 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 11:30:32, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1246, decode.acc_seg: 84.3587, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1896, mix.decode.acc_seg: 82.4312
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:54:05,549 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 11:28:59, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1730, decode.acc_seg: 83.0279, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2166, mix.decode.acc_seg: 81.2384
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:54:59,474 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 11:27:26, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1358, decode.acc_seg: 84.5187, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1945, mix.decode.acc_seg: 82.8973
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:55:53,474 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 11:25:55, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1749, decode.acc_seg: 83.1548, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2151, mix.decode.acc_seg: 81.9807
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:56:47,444 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 11:24:24, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.2214, decode.acc_seg: 83.7044, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2763, mix.decode.acc_seg: 80.9884
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:57:41,410 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 11:22:54, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1172, decode.acc_seg: 83.6650, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1933, mix.decode.acc_seg: 82.4758
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:58:35,378 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 11:21:25, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1416, decode.acc_seg: 85.1514, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1923, mix.decode.acc_seg: 83.8577
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 11:59:29,328 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 11:19:56, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1406, decode.acc_seg: 83.1916, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1933, mix.decode.acc_seg: 80.8824
2024-06-21 12:02:00,764 - mmseg - INFO - per class results:
2024-06-21 12:02:00,766 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 89.71 | 92.29 |
|    sidewalk   |  4.21 |  5.0  |
|    building   |  76.5 | 80.53 |
|      wall     | 16.21 | 20.28 |
|     fence     |  0.21 |  0.22 |
|      pole     |  nan  |  nan  |
| traffic light | 14.02 | 14.24 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 78.59 | 80.36 |
|    terrain    |  0.67 |  0.67 |
|      sky      | 90.53 | 96.44 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 72.01 |  73.5 |
|     truck     |  nan  |  nan  |
|      bus      | 45.96 | 65.38 |
|     train     |  nan  |  nan  |
|   motorcycle  |  15.1 | 15.43 |
|    bicycle    |  1.2  |  1.2  |
|    unknown    | 13.92 | 73.92 |
+---------------+-------+-------+
2024-06-21 12:02:00,766 - mmseg - INFO - Summary:
2024-06-21 12:02:00,766 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 78.08 | 37.06 | 44.25 |  20.49  |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:02:00,769 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 12:02:00,769 - mmseg - INFO - Iter [500/40000]	lr: 5.250e-05, eta: 11:18:30, time: 1.082, data_time: 0.014, memory: 9812, aAcc: 0.7808, mIoU: 0.3706, mAcc: 0.4425, IoU.road: 0.8971, IoU.sidewalk: 0.0421, IoU.building: 0.7650, IoU.wall: 0.1621, IoU.fence: 0.0021, IoU.pole: nan, IoU.traffic light: 0.1402, IoU.traffic sign: nan, IoU.vegetation: 0.7859, IoU.terrain: 0.0067, IoU.sky: 0.9053, IoU.person: nan, IoU.rider: nan, IoU.car: 0.7201, IoU.truck: nan, IoU.bus: 0.4596, IoU.train: nan, IoU.motorcycle: 0.1510, IoU.bicycle: 0.0120, IoU.unknown: 0.1392, Acc.road: 0.9229, Acc.sidewalk: 0.0500, Acc.building: 0.8053, Acc.wall: 0.2028, Acc.fence: 0.0022, Acc.pole: nan, Acc.traffic light: 0.1424, Acc.traffic sign: nan, Acc.vegetation: 0.8036, Acc.terrain: 0.0067, Acc.sky: 0.9644, Acc.person: nan, Acc.rider: nan, Acc.car: 0.7350, Acc.truck: nan, Acc.bus: 0.6538, Acc.train: nan, Acc.motorcycle: 0.1543, Acc.bicycle: 0.0120, Acc.unknown: 0.7392, decode.loss_ce: 0.1708, decode.acc_seg: 83.2340, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2171, mix.decode.acc_seg: 82.9315
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:02:56,803 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 11:28:30, time: 3.067, data_time: 1.961, memory: 9812, decode.loss_ce: 0.1468, decode.acc_seg: 84.3631, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1877, mix.decode.acc_seg: 83.5891
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:03:50,932 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 11:26:57, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1372, decode.acc_seg: 85.3322, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1842, mix.decode.acc_seg: 83.2560
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:04:44,950 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 11:25:24, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1180, decode.acc_seg: 83.0583, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1767, mix.decode.acc_seg: 83.0964
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:05:38,988 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 11:23:52, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1263, decode.acc_seg: 84.4173, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1827, mix.decode.acc_seg: 82.3212
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:06:32,977 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 11:22:20, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1691, decode.acc_seg: 82.8148, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2202, mix.decode.acc_seg: 82.1084
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:07:27,014 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 11:20:49, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1373, decode.acc_seg: 82.9920, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1704, mix.decode.acc_seg: 82.7674
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:08:21,133 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 11:19:20, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1480, decode.acc_seg: 85.2177, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1820, mix.decode.acc_seg: 83.1416
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:09:15,077 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 11:17:50, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1249, decode.acc_seg: 82.9107, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1785, mix.decode.acc_seg: 81.6012
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:10:09,009 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 11:16:20, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1251, decode.acc_seg: 85.0756, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1632, mix.decode.acc_seg: 83.9033
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:11:02,937 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 11:14:51, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1451, decode.acc_seg: 84.2298, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1776, mix.decode.acc_seg: 82.5930
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:11:58,337 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 11:13:32, time: 1.108, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1173, decode.acc_seg: 84.0073, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1612, mix.decode.acc_seg: 83.7254
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:12:52,547 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 11:12:06, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1308, decode.acc_seg: 85.5197, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1653, mix.decode.acc_seg: 85.0460
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:13:46,634 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 11:10:40, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1313, decode.acc_seg: 84.6293, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1645, mix.decode.acc_seg: 84.3610
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:14:40,632 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 11:09:14, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1875, decode.acc_seg: 83.9758, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2053, mix.decode.acc_seg: 82.4718
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:15:34,633 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 11:07:49, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1215, decode.acc_seg: 83.6810, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1683, mix.decode.acc_seg: 84.0272
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:16:28,622 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 11:06:24, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1799, decode.acc_seg: 83.1705, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2141, mix.decode.acc_seg: 81.6556
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:17:22,736 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 11:05:00, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1457, decode.acc_seg: 83.9549, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1756, mix.decode.acc_seg: 83.2827
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:18:16,819 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 11:03:36, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1710, decode.acc_seg: 84.3365, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.2045, mix.decode.acc_seg: 82.7343
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:19:10,772 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 11:02:13, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1585, decode.acc_seg: 84.6845, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1847, mix.decode.acc_seg: 84.5747
2024-06-21 12:21:41,030 - mmseg - INFO - per class results:
2024-06-21 12:21:41,031 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 85.83 | 86.74 |
|    sidewalk   |  0.43 |  0.45 |
|    building   | 41.46 | 41.68 |
|      wall     |  0.07 |  0.07 |
|     fence     |  0.11 |  0.11 |
|      pole     |  nan  |  nan  |
| traffic light |  9.24 |  9.32 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 68.31 | 69.08 |
|    terrain    |  3.13 |  3.14 |
|      sky      | 90.47 | 93.73 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 80.76 | 84.01 |
|     truck     |  nan  |  nan  |
|      bus      | 31.63 | 57.57 |
|     train     |  nan  |  nan  |
|   motorcycle  | 16.27 | 16.67 |
|    bicycle    |  0.27 |  0.27 |
|    unknown    |  10.3 | 90.87 |
+---------------+-------+-------+
2024-06-21 12:21:41,031 - mmseg - INFO - Summary:
2024-06-21 12:21:41,031 - mmseg - INFO - 
+-------+------+-------+---------+
|  aAcc | mIoU |  mAcc | H-Score |
+-------+------+-------+---------+
| 66.39 | 31.3 | 39.55 |  15.69  |
+-------+------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:21:41,034 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 12:21:41,034 - mmseg - INFO - Iter [500/40000]	lr: 5.100e-05, eta: 11:00:49, time: 1.080, data_time: 0.014, memory: 9812, aAcc: 0.6639, mIoU: 0.3130, mAcc: 0.3955, IoU.road: 0.8583, IoU.sidewalk: 0.0043, IoU.building: 0.4146, IoU.wall: 0.0007, IoU.fence: 0.0011, IoU.pole: nan, IoU.traffic light: 0.0924, IoU.traffic sign: nan, IoU.vegetation: 0.6831, IoU.terrain: 0.0313, IoU.sky: 0.9047, IoU.person: nan, IoU.rider: nan, IoU.car: 0.8076, IoU.truck: nan, IoU.bus: 0.3163, IoU.train: nan, IoU.motorcycle: 0.1627, IoU.bicycle: 0.0027, IoU.unknown: 0.1030, Acc.road: 0.8674, Acc.sidewalk: 0.0045, Acc.building: 0.4168, Acc.wall: 0.0007, Acc.fence: 0.0011, Acc.pole: nan, Acc.traffic light: 0.0932, Acc.traffic sign: nan, Acc.vegetation: 0.6908, Acc.terrain: 0.0314, Acc.sky: 0.9373, Acc.person: nan, Acc.rider: nan, Acc.car: 0.8401, Acc.truck: nan, Acc.bus: 0.5757, Acc.train: nan, Acc.motorcycle: 0.1667, Acc.bicycle: 0.0027, Acc.unknown: 0.9087, decode.loss_ce: 0.1426, decode.acc_seg: 84.5383, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1759, mix.decode.acc_seg: 83.2716
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:22:37,103 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 11:08:39, time: 3.047, data_time: 1.941, memory: 9812, decode.loss_ce: 0.1600, decode.acc_seg: 84.8660, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1899, mix.decode.acc_seg: 84.2676
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:23:31,248 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 11:07:12, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1355, decode.acc_seg: 84.3070, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1713, mix.decode.acc_seg: 83.1199
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:24:25,255 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 11:05:46, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1325, decode.acc_seg: 83.3441, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1567, mix.decode.acc_seg: 83.0524
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:25:19,411 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 11:04:20, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1383, decode.acc_seg: 83.4652, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1613, mix.decode.acc_seg: 84.0713
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:26:13,665 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 11:02:56, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1191, decode.acc_seg: 84.2833, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1618, mix.decode.acc_seg: 83.7306
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:27:07,775 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 11:01:31, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1179, decode.acc_seg: 85.3376, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1418, mix.decode.acc_seg: 83.9615
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:28:01,693 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 11:00:06, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1179, decode.acc_seg: 84.1965, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1526, mix.decode.acc_seg: 85.6671
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:28:55,594 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 10:58:41, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1532, decode.acc_seg: 83.7701, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1866, mix.decode.acc_seg: 82.8520
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:29:49,587 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 10:57:17, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1205, decode.acc_seg: 83.8261, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1414, mix.decode.acc_seg: 83.1159
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:30:43,730 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 10:55:54, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1153, decode.acc_seg: 86.3462, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1396, mix.decode.acc_seg: 85.5751
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:31:39,292 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 10:54:39, time: 1.111, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1489, decode.acc_seg: 82.2699, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1771, mix.decode.acc_seg: 83.9147
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:32:33,379 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 10:53:17, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1276, decode.acc_seg: 83.6149, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1661, mix.decode.acc_seg: 85.0144
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:33:27,621 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 10:51:56, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1547, decode.acc_seg: 83.1504, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1550, mix.decode.acc_seg: 83.9568
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:34:21,688 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 10:50:35, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1123, decode.acc_seg: 87.1838, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1438, mix.decode.acc_seg: 86.8980
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:35:15,676 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 10:49:14, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1362, decode.acc_seg: 84.3846, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1454, mix.decode.acc_seg: 86.0241
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:36:09,850 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 10:47:53, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1445, decode.acc_seg: 83.9689, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1551, mix.decode.acc_seg: 84.5880
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:37:03,924 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 10:46:33, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1172, decode.acc_seg: 85.1903, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1396, mix.decode.acc_seg: 83.2738
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:37:57,908 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 10:45:13, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1181, decode.acc_seg: 81.4921, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1416, mix.decode.acc_seg: 85.0519
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:38:52,085 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 10:43:54, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1454, decode.acc_seg: 83.9290, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1611, mix.decode.acc_seg: 83.6953
2024-06-21 12:41:21,121 - mmseg - INFO - per class results:
2024-06-21 12:41:21,122 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 84.64 | 85.68 |
|    sidewalk   |  0.85 |  1.0  |
|    building   | 13.32 | 13.33 |
|      wall     |  4.84 |  5.35 |
|     fence     |  0.0  |  0.0  |
|      pole     |  nan  |  nan  |
| traffic light |  1.2  |  1.21 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 60.68 | 61.05 |
|    terrain    |  1.5  |  1.52 |
|      sky      |  86.4 | 87.51 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 51.39 | 51.52 |
|     truck     |  nan  |  nan  |
|      bus      | 13.69 | 14.96 |
|     train     |  nan  |  nan  |
|   motorcycle  |  2.95 |  2.96 |
|    bicycle    |  0.01 |  0.01 |
|    unknown    |  8.62 | 97.75 |
+---------------+-------+-------+
2024-06-21 12:41:21,123 - mmseg - INFO - Summary:
2024-06-21 12:41:21,123 - mmseg - INFO - 
+------+-------+-------+---------+
| aAcc |  mIoU |  mAcc | H-Score |
+------+-------+-------+---------+
| 56.2 | 23.58 | 30.27 |  12.78  |
+------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:41:21,125 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 12:41:21,125 - mmseg - INFO - Iter [500/40000]	lr: 4.950e-05, eta: 10:42:35, time: 1.083, data_time: 0.015, memory: 9812, aAcc: 0.5620, mIoU: 0.2358, mAcc: 0.3027, IoU.road: 0.8464, IoU.sidewalk: 0.0085, IoU.building: 0.1332, IoU.wall: 0.0484, IoU.fence: 0.0000, IoU.pole: nan, IoU.traffic light: 0.0120, IoU.traffic sign: nan, IoU.vegetation: 0.6068, IoU.terrain: 0.0150, IoU.sky: 0.8640, IoU.person: nan, IoU.rider: nan, IoU.car: 0.5139, IoU.truck: nan, IoU.bus: 0.1369, IoU.train: nan, IoU.motorcycle: 0.0295, IoU.bicycle: 0.0001, IoU.unknown: 0.0862, Acc.road: 0.8568, Acc.sidewalk: 0.0100, Acc.building: 0.1333, Acc.wall: 0.0535, Acc.fence: 0.0000, Acc.pole: nan, Acc.traffic light: 0.0121, Acc.traffic sign: nan, Acc.vegetation: 0.6105, Acc.terrain: 0.0152, Acc.sky: 0.8751, Acc.person: nan, Acc.rider: nan, Acc.car: 0.5152, Acc.truck: nan, Acc.bus: 0.1496, Acc.train: nan, Acc.motorcycle: 0.0296, Acc.bicycle: 0.0001, Acc.unknown: 0.9775, decode.loss_ce: 0.1320, decode.acc_seg: 86.5669, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1481, mix.decode.acc_seg: 86.1038
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:42:17,185 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 10:48:49, time: 3.019, data_time: 1.913, memory: 9812, decode.loss_ce: 0.1190, decode.acc_seg: 86.6654, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1394, mix.decode.acc_seg: 87.1930
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:43:11,295 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 10:47:27, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1303, decode.acc_seg: 86.3873, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1518, mix.decode.acc_seg: 85.4646
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:44:05,345 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 10:46:05, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1211, decode.acc_seg: 86.8499, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1262, mix.decode.acc_seg: 86.5752
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:44:59,326 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 10:44:44, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1307, decode.acc_seg: 82.9716, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1273, mix.decode.acc_seg: 85.1147
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:45:53,321 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 10:43:22, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1262, decode.acc_seg: 85.3399, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1549, mix.decode.acc_seg: 84.2433
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:46:47,250 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 10:42:01, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1134, decode.acc_seg: 84.4409, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1203, mix.decode.acc_seg: 86.2307
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:47:41,267 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 10:40:40, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1172, decode.acc_seg: 85.5013, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1287, mix.decode.acc_seg: 85.7847
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:48:35,395 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 10:39:20, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1315, decode.acc_seg: 84.2631, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1556, mix.decode.acc_seg: 85.3926
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:49:29,379 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 10:38:00, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1459, decode.acc_seg: 84.7368, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1678, mix.decode.acc_seg: 84.8539
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:50:23,309 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 10:36:40, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.0984, decode.acc_seg: 85.8756, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1280, mix.decode.acc_seg: 86.6597
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:51:18,872 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 10:35:28, time: 1.111, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1215, decode.acc_seg: 84.1469, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1828, mix.decode.acc_seg: 84.7316
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:52:12,902 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 10:34:09, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1382, decode.acc_seg: 82.7297, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1541, mix.decode.acc_seg: 85.2473
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:53:06,813 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 10:32:50, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1709, decode.acc_seg: 83.6389, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1433, mix.decode.acc_seg: 85.8711
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:54:00,811 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 10:31:32, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1185, decode.acc_seg: 85.3189, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1366, mix.decode.acc_seg: 87.5779
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:54:54,977 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 10:30:14, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1255, decode.acc_seg: 86.2836, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1656, mix.decode.acc_seg: 86.7620
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:55:48,969 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 10:28:56, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1098, decode.acc_seg: 85.6434, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1174, mix.decode.acc_seg: 87.5294
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:56:43,070 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 10:27:39, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1089, decode.acc_seg: 85.0333, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1158, mix.decode.acc_seg: 85.8744
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:57:37,222 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 10:26:23, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1009, decode.acc_seg: 84.9405, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1215, mix.decode.acc_seg: 86.9375
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 12:58:31,380 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 10:25:07, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1549, decode.acc_seg: 83.4260, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1674, mix.decode.acc_seg: 84.9963
2024-06-21 13:00:59,833 - mmseg - INFO - per class results:
2024-06-21 13:00:59,835 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 75.18 | 75.54 |
|    sidewalk   |  0.04 |  0.04 |
|    building   |  1.36 |  1.36 |
|      wall     |  0.57 |  0.58 |
|     fence     |  0.45 |  0.46 |
|      pole     |  nan  |  nan  |
| traffic light |  2.69 |  2.7  |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 50.01 | 50.24 |
|    terrain    |  1.54 |  1.56 |
|      sky      |  74.6 | 81.37 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 65.81 | 68.38 |
|     truck     |  nan  |  nan  |
|      bus      |  0.18 |  0.18 |
|     train     |  nan  |  nan  |
|   motorcycle  |  3.39 |  3.39 |
|    bicycle    |  0.12 |  0.12 |
|    unknown    |  7.27 | 97.28 |
+---------------+-------+-------+
2024-06-21 13:00:59,835 - mmseg - INFO - Summary:
2024-06-21 13:00:59,835 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 48.62 | 20.23 | 27.37 |  10.83  |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:00:59,837 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 13:00:59,838 - mmseg - INFO - Iter [500/40000]	lr: 4.800e-05, eta: 10:23:51, time: 1.083, data_time: 0.015, memory: 9812, aAcc: 0.4862, mIoU: 0.2023, mAcc: 0.2737, IoU.road: 0.7518, IoU.sidewalk: 0.0004, IoU.building: 0.0136, IoU.wall: 0.0057, IoU.fence: 0.0045, IoU.pole: nan, IoU.traffic light: 0.0269, IoU.traffic sign: nan, IoU.vegetation: 0.5001, IoU.terrain: 0.0154, IoU.sky: 0.7460, IoU.person: nan, IoU.rider: nan, IoU.car: 0.6581, IoU.truck: nan, IoU.bus: 0.0018, IoU.train: nan, IoU.motorcycle: 0.0339, IoU.bicycle: 0.0012, IoU.unknown: 0.0727, Acc.road: 0.7554, Acc.sidewalk: 0.0004, Acc.building: 0.0136, Acc.wall: 0.0058, Acc.fence: 0.0046, Acc.pole: nan, Acc.traffic light: 0.0270, Acc.traffic sign: nan, Acc.vegetation: 0.5024, Acc.terrain: 0.0156, Acc.sky: 0.8137, Acc.person: nan, Acc.rider: nan, Acc.car: 0.6838, Acc.truck: nan, Acc.bus: 0.0018, Acc.train: nan, Acc.motorcycle: 0.0339, Acc.bicycle: 0.0012, Acc.unknown: 0.9728, decode.loss_ce: 0.1348, decode.acc_seg: 84.0937, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1843, mix.decode.acc_seg: 83.6054
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:01:55,782 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 10:28:56, time: 3.005, data_time: 1.901, memory: 9812, decode.loss_ce: 0.1916, decode.acc_seg: 81.8559, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1913, mix.decode.acc_seg: 83.3700
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:02:49,925 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 10:27:38, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1427, decode.acc_seg: 84.5903, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1541, mix.decode.acc_seg: 85.3623
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:03:43,931 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 10:26:19, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1182, decode.acc_seg: 85.0490, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1225, mix.decode.acc_seg: 86.1901
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:04:38,049 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 10:25:02, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1649, decode.acc_seg: 83.0951, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1735, mix.decode.acc_seg: 85.0356
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:05:32,230 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 10:23:44, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1302, decode.acc_seg: 82.7197, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1447, mix.decode.acc_seg: 85.9316
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:06:26,375 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 10:22:27, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1279, decode.acc_seg: 85.3894, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1262, mix.decode.acc_seg: 87.5831
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:07:20,373 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 10:21:09, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1060, decode.acc_seg: 85.3929, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1243, mix.decode.acc_seg: 86.5474
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:08:14,402 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 10:19:52, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1145, decode.acc_seg: 84.6197, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1308, mix.decode.acc_seg: 86.8006
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:09:08,592 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 10:18:36, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0989, decode.acc_seg: 82.9369, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1257, mix.decode.acc_seg: 85.5294
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:10:02,612 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 10:17:19, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1118, decode.acc_seg: 86.2773, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1248, mix.decode.acc_seg: 86.7939
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:10:58,114 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 10:16:09, time: 1.110, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1212, decode.acc_seg: 84.7893, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1288, mix.decode.acc_seg: 86.3704
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:11:52,137 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 10:14:52, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1084, decode.acc_seg: 83.8387, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1263, mix.decode.acc_seg: 85.3784
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:12:46,151 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 10:13:36, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1186, decode.acc_seg: 85.5130, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1450, mix.decode.acc_seg: 88.2547
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:13:40,276 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 10:12:21, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1186, decode.acc_seg: 84.2910, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1393, mix.decode.acc_seg: 86.0346
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:14:34,463 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 10:11:06, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1036, decode.acc_seg: 83.9723, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1254, mix.decode.acc_seg: 86.2267
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:15:28,585 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 10:09:52, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1074, decode.acc_seg: 85.5575, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1209, mix.decode.acc_seg: 87.9346
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:16:22,703 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 10:08:37, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1143, decode.acc_seg: 84.2777, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1431, mix.decode.acc_seg: 84.7633
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:17:16,690 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 10:07:22, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1233, decode.acc_seg: 85.4075, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1315, mix.decode.acc_seg: 86.4808
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:18:10,617 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 10:06:08, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1191, decode.acc_seg: 85.6575, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1441, mix.decode.acc_seg: 87.7557
2024-06-21 13:20:39,797 - mmseg - INFO - per class results:
2024-06-21 13:20:39,798 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 79.91 | 80.56 |
|    sidewalk   |  0.02 |  0.02 |
|    building   |  4.27 |  4.28 |
|      wall     |  1.89 |  1.94 |
|     fence     |  0.69 |  0.7  |
|      pole     |  nan  |  nan  |
| traffic light |  4.06 |  4.07 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 37.03 | 37.13 |
|    terrain    |  1.02 |  1.03 |
|      sky      | 70.02 | 70.68 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 56.07 | 56.47 |
|     truck     |  nan  |  nan  |
|      bus      | 17.48 | 19.97 |
|     train     |  nan  |  nan  |
|   motorcycle  |  5.2  |  5.21 |
|    bicycle    |  0.19 |  0.19 |
|    unknown    |  7.16 |  97.9 |
+---------------+-------+-------+
2024-06-21 13:20:39,798 - mmseg - INFO - Summary:
2024-06-21 13:20:39,799 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 47.86 | 20.36 | 27.15 |  10.73  |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:20:39,801 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 13:20:39,801 - mmseg - INFO - Iter [500/40000]	lr: 4.650e-05, eta: 10:04:54, time: 1.082, data_time: 0.015, memory: 9812, aAcc: 0.4786, mIoU: 0.2036, mAcc: 0.2715, IoU.road: 0.7991, IoU.sidewalk: 0.0002, IoU.building: 0.0427, IoU.wall: 0.0189, IoU.fence: 0.0069, IoU.pole: nan, IoU.traffic light: 0.0406, IoU.traffic sign: nan, IoU.vegetation: 0.3703, IoU.terrain: 0.0102, IoU.sky: 0.7002, IoU.person: nan, IoU.rider: nan, IoU.car: 0.5607, IoU.truck: nan, IoU.bus: 0.1748, IoU.train: nan, IoU.motorcycle: 0.0520, IoU.bicycle: 0.0019, IoU.unknown: 0.0716, Acc.road: 0.8056, Acc.sidewalk: 0.0002, Acc.building: 0.0428, Acc.wall: 0.0194, Acc.fence: 0.0070, Acc.pole: nan, Acc.traffic light: 0.0407, Acc.traffic sign: nan, Acc.vegetation: 0.3713, Acc.terrain: 0.0103, Acc.sky: 0.7068, Acc.person: nan, Acc.rider: nan, Acc.car: 0.5647, Acc.truck: nan, Acc.bus: 0.1997, Acc.train: nan, Acc.motorcycle: 0.0521, Acc.bicycle: 0.0019, Acc.unknown: 0.9790, decode.loss_ce: 0.1149, decode.acc_seg: 85.4024, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1431, mix.decode.acc_seg: 86.2561
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:21:35,729 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 10:09:11, time: 3.020, data_time: 1.916, memory: 9812, decode.loss_ce: 0.1195, decode.acc_seg: 84.0968, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1368, mix.decode.acc_seg: 87.1132
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:22:29,901 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 10:07:56, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1156, decode.acc_seg: 86.0960, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1284, mix.decode.acc_seg: 87.1398
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:23:24,113 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 10:06:40, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1245, decode.acc_seg: 83.9304, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1527, mix.decode.acc_seg: 85.5279
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:24:18,234 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 10:05:25, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1762, decode.acc_seg: 85.1489, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1605, mix.decode.acc_seg: 86.2466
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:25:12,271 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 10:04:10, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1263, decode.acc_seg: 83.3608, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1361, mix.decode.acc_seg: 85.3008
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:26:06,190 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 10:02:54, time: 1.078, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1228, decode.acc_seg: 84.2166, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1440, mix.decode.acc_seg: 86.7469
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:27:00,265 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 10:01:39, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1280, decode.acc_seg: 84.4494, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1215, mix.decode.acc_seg: 86.2482
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:27:54,256 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 10:00:25, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1157, decode.acc_seg: 83.7966, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1498, mix.decode.acc_seg: 85.6320
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:28:48,231 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 9:59:10, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1255, decode.acc_seg: 85.7493, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1718, mix.decode.acc_seg: 85.8647
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:29:42,268 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 9:57:56, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1132, decode.acc_seg: 86.6360, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1338, mix.decode.acc_seg: 87.3915
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:30:37,897 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 9:56:47, time: 1.113, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1284, decode.acc_seg: 84.7000, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1271, mix.decode.acc_seg: 86.8862
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:31:32,007 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 9:55:33, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1216, decode.acc_seg: 83.6729, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1189, mix.decode.acc_seg: 86.8632
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:32:26,137 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 9:54:20, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1005, decode.acc_seg: 85.1640, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1204, mix.decode.acc_seg: 87.0577
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:33:20,311 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 9:53:07, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1117, decode.acc_seg: 84.9371, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1258, mix.decode.acc_seg: 86.0429
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:34:14,550 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 9:51:54, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1237, decode.acc_seg: 85.2323, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1193, mix.decode.acc_seg: 87.3949
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:35:08,677 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 9:50:41, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0915, decode.acc_seg: 86.1792, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1034, mix.decode.acc_seg: 88.5837
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:36:02,914 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 9:49:29, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1359, decode.acc_seg: 84.1147, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1521, mix.decode.acc_seg: 84.9300
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:36:56,863 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 9:48:16, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1108, decode.acc_seg: 84.8110, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1394, mix.decode.acc_seg: 87.8034
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:37:50,816 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 9:47:03, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1111, decode.acc_seg: 83.8285, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1292, mix.decode.acc_seg: 85.6794
2024-06-21 13:40:18,123 - mmseg - INFO - per class results:
2024-06-21 13:40:18,125 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 62.95 | 63.08 |
|    sidewalk   |  1.36 |  1.71 |
|    building   |  0.36 |  0.36 |
|      wall     |  1.58 |  1.63 |
|     fence     |  0.39 |  0.39 |
|      pole     |  nan  |  nan  |
| traffic light |  1.52 |  1.52 |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 18.93 | 18.95 |
|    terrain    |  3.24 |  3.29 |
|      sky      | 53.95 | 54.11 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      |  23.9 | 23.95 |
|     truck     |  nan  |  nan  |
|      bus      |  7.83 |  8.49 |
|     train     |  nan  |  nan  |
|   motorcycle  |  0.72 |  0.72 |
|    bicycle    |  0.01 |  0.01 |
|    unknown    |  5.95 | 99.08 |
+---------------+-------+-------+
2024-06-21 13:40:18,125 - mmseg - INFO - Summary:
2024-06-21 13:40:18,125 - mmseg - INFO - 
+------+-------+-------+---------+
| aAcc |  mIoU |  mAcc | H-Score |
+------+-------+-------+---------+
| 34.7 | 13.05 | 19.81 |   8.28  |
+------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:40:18,127 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 13:40:18,127 - mmseg - INFO - Iter [500/40000]	lr: 4.500e-05, eta: 9:45:51, time: 1.084, data_time: 0.015, memory: 9812, aAcc: 0.3470, mIoU: 0.1305, mAcc: 0.1981, IoU.road: 0.6295, IoU.sidewalk: 0.0136, IoU.building: 0.0036, IoU.wall: 0.0158, IoU.fence: 0.0039, IoU.pole: nan, IoU.traffic light: 0.0152, IoU.traffic sign: nan, IoU.vegetation: 0.1893, IoU.terrain: 0.0324, IoU.sky: 0.5395, IoU.person: nan, IoU.rider: nan, IoU.car: 0.2390, IoU.truck: nan, IoU.bus: 0.0783, IoU.train: nan, IoU.motorcycle: 0.0072, IoU.bicycle: 0.0001, IoU.unknown: 0.0595, Acc.road: 0.6308, Acc.sidewalk: 0.0171, Acc.building: 0.0036, Acc.wall: 0.0163, Acc.fence: 0.0039, Acc.pole: nan, Acc.traffic light: 0.0152, Acc.traffic sign: nan, Acc.vegetation: 0.1895, Acc.terrain: 0.0329, Acc.sky: 0.5411, Acc.person: nan, Acc.rider: nan, Acc.car: 0.2395, Acc.truck: nan, Acc.bus: 0.0849, Acc.train: nan, Acc.motorcycle: 0.0072, Acc.bicycle: 0.0001, Acc.unknown: 0.9908, decode.loss_ce: 0.1110, decode.acc_seg: 85.9155, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1173, mix.decode.acc_seg: 88.6343
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:41:14,123 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 9:49:23, time: 2.982, data_time: 1.877, memory: 9812, decode.loss_ce: 0.1065, decode.acc_seg: 84.1254, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1158, mix.decode.acc_seg: 86.8630
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:42:08,117 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 9:48:09, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1128, decode.acc_seg: 84.0660, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1258, mix.decode.acc_seg: 86.7157
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:43:02,074 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 9:46:55, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1288, decode.acc_seg: 84.1282, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1404, mix.decode.acc_seg: 86.9720
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:43:56,113 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 9:45:41, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0998, decode.acc_seg: 85.7181, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1200, mix.decode.acc_seg: 87.3893
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:44:50,117 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 9:44:28, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1038, decode.acc_seg: 86.8232, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1192, mix.decode.acc_seg: 87.6219
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:45:44,433 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 9:43:16, time: 1.086, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1191, decode.acc_seg: 82.6877, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1522, mix.decode.acc_seg: 85.6291
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:46:38,597 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 9:42:03, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1309, decode.acc_seg: 85.1962, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1293, mix.decode.acc_seg: 87.9593
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:47:32,658 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 9:40:50, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1187, decode.acc_seg: 84.9514, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1345, mix.decode.acc_seg: 86.8651
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:48:26,760 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 9:39:38, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1072, decode.acc_seg: 86.2091, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1177, mix.decode.acc_seg: 87.5137
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:49:20,817 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 9:38:26, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1127, decode.acc_seg: 85.8246, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1283, mix.decode.acc_seg: 86.6189
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:50:16,369 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 9:37:18, time: 1.111, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1134, decode.acc_seg: 84.2682, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1305, mix.decode.acc_seg: 86.1760
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:51:10,373 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 9:36:06, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1072, decode.acc_seg: 84.1795, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1159, mix.decode.acc_seg: 86.0154
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:52:04,546 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 9:34:54, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1565, decode.acc_seg: 82.8996, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1511, mix.decode.acc_seg: 85.9347
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:52:58,748 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 9:33:43, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1027, decode.acc_seg: 85.2766, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1145, mix.decode.acc_seg: 87.6434
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:53:52,816 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 9:32:32, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1386, decode.acc_seg: 84.7283, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1018, mix.decode.acc_seg: 87.8396
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:54:46,790 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 9:31:20, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1104, decode.acc_seg: 85.2125, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1123, mix.decode.acc_seg: 88.9567
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:55:40,904 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 9:30:09, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1047, decode.acc_seg: 85.9818, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1069, mix.decode.acc_seg: 87.5944
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:56:35,068 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 9:28:58, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1241, decode.acc_seg: 85.8981, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1522, mix.decode.acc_seg: 87.4883
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:57:29,292 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 9:27:48, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1143, decode.acc_seg: 85.2702, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1295, mix.decode.acc_seg: 86.8642
2024-06-21 13:59:57,628 - mmseg - INFO - per class results:
2024-06-21 13:59:57,630 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 69.01 | 69.49 |
|    sidewalk   |  1.02 |  1.07 |
|    building   |  5.0  |  5.01 |
|      wall     | 16.42 | 17.41 |
|     fence     |  4.27 |  4.73 |
|      pole     |  nan  |  nan  |
| traffic light |  6.44 |  6.5  |
|  traffic sign |  nan  |  nan  |
|   vegetation  | 21.19 | 21.35 |
|    terrain    |  3.63 |  3.69 |
|      sky      | 56.15 | 56.73 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 37.98 |  38.2 |
|     truck     |  nan  |  nan  |
|      bus      | 20.89 | 25.24 |
|     train     |  nan  |  nan  |
|   motorcycle  |  5.47 |  5.55 |
|    bicycle    |  1.19 |  1.19 |
|    unknown    |  6.21 | 96.66 |
+---------------+-------+-------+
2024-06-21 13:59:57,630 - mmseg - INFO - Summary:
2024-06-21 13:59:57,630 - mmseg - INFO - 
+-------+------+------+---------+
|  aAcc | mIoU | mAcc | H-Score |
+-------+------+------+---------+
| 39.67 | 18.2 | 25.2 |   9.38  |
+-------+------+------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 13:59:57,633 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 13:59:57,633 - mmseg - INFO - Iter [500/40000]	lr: 4.350e-05, eta: 9:26:38, time: 1.085, data_time: 0.015, memory: 9812, aAcc: 0.3967, mIoU: 0.1820, mAcc: 0.2520, IoU.road: 0.6901, IoU.sidewalk: 0.0102, IoU.building: 0.0500, IoU.wall: 0.1642, IoU.fence: 0.0427, IoU.pole: nan, IoU.traffic light: 0.0644, IoU.traffic sign: nan, IoU.vegetation: 0.2119, IoU.terrain: 0.0363, IoU.sky: 0.5615, IoU.person: nan, IoU.rider: nan, IoU.car: 0.3798, IoU.truck: nan, IoU.bus: 0.2089, IoU.train: nan, IoU.motorcycle: 0.0547, IoU.bicycle: 0.0119, IoU.unknown: 0.0621, Acc.road: 0.6949, Acc.sidewalk: 0.0107, Acc.building: 0.0501, Acc.wall: 0.1741, Acc.fence: 0.0473, Acc.pole: nan, Acc.traffic light: 0.0650, Acc.traffic sign: nan, Acc.vegetation: 0.2135, Acc.terrain: 0.0369, Acc.sky: 0.5673, Acc.person: nan, Acc.rider: nan, Acc.car: 0.3820, Acc.truck: nan, Acc.bus: 0.2524, Acc.train: nan, Acc.motorcycle: 0.0555, Acc.bicycle: 0.0119, Acc.unknown: 0.9666, decode.loss_ce: 0.1041, decode.acc_seg: 85.4119, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1115, mix.decode.acc_seg: 86.9683
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:00:53,604 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 9:29:39, time: 3.001, data_time: 1.896, memory: 9812, decode.loss_ce: 0.1179, decode.acc_seg: 84.9117, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1271, mix.decode.acc_seg: 87.2563
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:01:47,698 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 9:28:27, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1170, decode.acc_seg: 85.1534, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1266, mix.decode.acc_seg: 85.8570
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:02:41,675 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 9:27:15, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1056, decode.acc_seg: 84.9165, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1163, mix.decode.acc_seg: 86.8219
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:03:35,663 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 9:26:03, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1231, decode.acc_seg: 84.0955, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1297, mix.decode.acc_seg: 85.1014
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:04:29,620 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 9:24:51, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1165, decode.acc_seg: 84.7139, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1216, mix.decode.acc_seg: 87.9781
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:05:23,730 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 9:23:40, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1647, decode.acc_seg: 83.3769, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1746, mix.decode.acc_seg: 84.7982
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:06:17,999 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 9:22:29, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1642, decode.acc_seg: 82.9054, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1476, mix.decode.acc_seg: 85.0011
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:07:12,142 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 9:21:18, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1425, decode.acc_seg: 84.7587, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1269, mix.decode.acc_seg: 86.8022
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:08:06,287 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 9:20:08, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1053, decode.acc_seg: 84.2177, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1068, mix.decode.acc_seg: 86.1133
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:09:00,264 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 9:18:57, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1218, decode.acc_seg: 86.7728, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1090, mix.decode.acc_seg: 87.8498
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:09:55,720 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 9:17:49, time: 1.109, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1200, decode.acc_seg: 85.6837, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1189, mix.decode.acc_seg: 87.5052
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:10:49,828 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 9:16:39, time: 1.082, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1350, decode.acc_seg: 84.2418, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1445, mix.decode.acc_seg: 84.5364
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:11:44,007 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 9:15:29, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1220, decode.acc_seg: 83.9364, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1191, mix.decode.acc_seg: 86.5191
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:12:38,047 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 9:14:19, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0995, decode.acc_seg: 85.4173, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1032, mix.decode.acc_seg: 87.4358
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:13:32,111 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 9:13:09, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1061, decode.acc_seg: 85.8814, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1014, mix.decode.acc_seg: 88.3290
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:14:26,087 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 9:11:59, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1107, decode.acc_seg: 85.1073, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1134, mix.decode.acc_seg: 88.9049
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:15:20,258 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 9:10:49, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1016, decode.acc_seg: 87.5783, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1113, mix.decode.acc_seg: 88.8771
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:16:14,338 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 9:09:39, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0963, decode.acc_seg: 83.8825, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1006, mix.decode.acc_seg: 87.0187
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:17:08,463 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 9:08:30, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0888, decode.acc_seg: 85.9212, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0944, mix.decode.acc_seg: 88.0173
2024-06-21 14:19:36,809 - mmseg - INFO - per class results:
2024-06-21 14:19:36,810 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 58.08 | 58.36 |
|    sidewalk   |  1.4  |  1.48 |
|    building   |  0.98 |  0.99 |
|      wall     | 12.25 |  13.6 |
|     fence     |  2.25 |  2.38 |
|      pole     |  nan  |  nan  |
| traffic light |  4.58 |  4.61 |
|  traffic sign |  nan  |  nan  |
|   vegetation  |  6.02 |  6.03 |
|    terrain    |  1.89 |  1.9  |
|      sky      | 26.28 | 26.29 |
|     person    |  nan  |  nan  |
|     rider     |  nan  |  nan  |
|      car      | 28.64 | 28.82 |
|     truck     |  nan  |  nan  |
|      bus      | 19.56 | 21.26 |
|     train     |  nan  |  nan  |
|   motorcycle  |  5.68 |  5.73 |
|    bicycle    |  0.69 |  0.69 |
|    unknown    |  5.52 |  98.9 |
+---------------+-------+-------+
2024-06-21 14:19:36,810 - mmseg - INFO - Summary:
2024-06-21 14:19:36,810 - mmseg - INFO - 
+-------+-------+-------+---------+
|  aAcc |  mIoU |  mAcc | H-Score |
+-------+-------+-------+---------+
| 30.34 | 12.42 | 19.36 |   7.74  |
+-------+-------+-------+---------+
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:19:36,812 - mmseg - INFO - Exp name: 240621_1022_gta2cs_tau7_unknown_warm4000_OS_s0_d1b41
2024-06-21 14:19:36,813 - mmseg - INFO - Iter [500/40000]	lr: 4.200e-05, eta: 9:07:21, time: 1.081, data_time: 0.015, memory: 9812, aAcc: 0.3034, mIoU: 0.1242, mAcc: 0.1936, IoU.road: 0.5808, IoU.sidewalk: 0.0140, IoU.building: 0.0098, IoU.wall: 0.1225, IoU.fence: 0.0225, IoU.pole: nan, IoU.traffic light: 0.0458, IoU.traffic sign: nan, IoU.vegetation: 0.0602, IoU.terrain: 0.0189, IoU.sky: 0.2628, IoU.person: nan, IoU.rider: nan, IoU.car: 0.2864, IoU.truck: nan, IoU.bus: 0.1956, IoU.train: nan, IoU.motorcycle: 0.0568, IoU.bicycle: 0.0069, IoU.unknown: 0.0552, Acc.road: 0.5836, Acc.sidewalk: 0.0148, Acc.building: 0.0099, Acc.wall: 0.1360, Acc.fence: 0.0238, Acc.pole: nan, Acc.traffic light: 0.0461, Acc.traffic sign: nan, Acc.vegetation: 0.0603, Acc.terrain: 0.0190, Acc.sky: 0.2629, Acc.person: nan, Acc.rider: nan, Acc.car: 0.2882, Acc.truck: nan, Acc.bus: 0.2126, Acc.train: nan, Acc.motorcycle: 0.0573, Acc.bicycle: 0.0069, Acc.unknown: 0.9890, decode.loss_ce: 0.0954, decode.acc_seg: 85.1461, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1083, mix.decode.acc_seg: 87.6276
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:20:32,797 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 9:09:55, time: 3.005, data_time: 1.900, memory: 9812, decode.loss_ce: 0.0920, decode.acc_seg: 87.9218, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0984, mix.decode.acc_seg: 89.8365
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:21:26,878 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 9:08:44, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1012, decode.acc_seg: 86.7125, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0990, mix.decode.acc_seg: 87.5013
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:22:20,958 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 9:07:34, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1380, decode.acc_seg: 84.8253, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1088, mix.decode.acc_seg: 88.3166
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:23:15,149 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 9:06:24, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1210, decode.acc_seg: 84.9593, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1166, mix.decode.acc_seg: 88.2030
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:24:09,200 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 9:05:14, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1158, decode.acc_seg: 86.2363, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1074, mix.decode.acc_seg: 87.1071
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:25:03,137 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 9:04:04, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1088, decode.acc_seg: 84.9650, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1079, mix.decode.acc_seg: 86.7269
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:25:57,178 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 9:02:54, time: 1.081, data_time: 0.014, memory: 9812, decode.loss_ce: 0.0999, decode.acc_seg: 85.1224, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0972, mix.decode.acc_seg: 87.1277
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:26:51,201 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 9:01:44, time: 1.080, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1021, decode.acc_seg: 84.9291, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1094, mix.decode.acc_seg: 86.1344
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:27:45,222 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 9:00:34, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.0956, decode.acc_seg: 85.6986, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1026, mix.decode.acc_seg: 87.8668
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:28:39,154 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 8:59:25, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1304, decode.acc_seg: 82.5920, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1068, mix.decode.acc_seg: 84.6049
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:29:34,818 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 8:58:19, time: 1.113, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1004, decode.acc_seg: 85.6224, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0906, mix.decode.acc_seg: 86.9770
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:30:28,972 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 8:57:10, time: 1.083, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1079, decode.acc_seg: 84.3191, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1134, mix.decode.acc_seg: 88.9611
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:31:23,239 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 8:56:01, time: 1.085, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1066, decode.acc_seg: 84.6006, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1020, mix.decode.acc_seg: 87.0947
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:32:17,349 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 8:54:52, time: 1.082, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1018, decode.acc_seg: 84.4642, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1001, mix.decode.acc_seg: 89.5789
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:33:11,320 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 8:53:43, time: 1.079, data_time: 0.014, memory: 9812, decode.loss_ce: 0.1022, decode.acc_seg: 84.4027, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0894, mix.decode.acc_seg: 87.4917
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:34:05,513 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 8:52:35, time: 1.084, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1597, decode.acc_seg: 84.3140, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1549, mix.decode.acc_seg: 86.1067
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:34:59,515 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 8:51:26, time: 1.080, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1035, decode.acc_seg: 85.2632, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.1193, mix.decode.acc_seg: 87.7481
/data/users/wangad0448/.conda/envs/daformer_2/lib/python3.8/site-packages/mmcv/runner/hooks/logger/text.py:55: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.
  mem_mb = torch.tensor([mem / (1024 * 1024)],
2024-06-21 14:35:53,565 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 8:50:17, time: 1.081, data_time: 0.015, memory: 9812, decode.loss_ce: 0.1040, decode.acc_seg: 85.4295, src.loss_imnet_feat_dist: nan, mix.decode.loss_ce: 0.0963, mix.decode.acc_seg: 87.7112
slurmstepd: error: *** JOB 81950 ON gpu03 CANCELLED AT 2024-06-21T14:36:43 ***
